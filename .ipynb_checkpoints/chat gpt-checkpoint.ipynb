{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e034924b",
   "metadata": {},
   "source": [
    "### 1.导入所需的库：cv2用于读取视频文件，numpy用于数据处理，os用于管理文件系统，keras用于创建和训练深度学习模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "304ec5e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tkinter import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cff7a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('sean.mp4')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2cae58d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "success,image = cap.read()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b60972b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b2c39fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 17,  12,  13],\n",
       "        [ 17,  12,  13],\n",
       "        [ 17,  12,  13],\n",
       "        ...,\n",
       "        [136, 124, 136],\n",
       "        [136, 124, 136],\n",
       "        [136, 124, 136]],\n",
       "\n",
       "       [[ 17,  12,  13],\n",
       "        [ 17,  12,  13],\n",
       "        [ 17,  12,  13],\n",
       "        ...,\n",
       "        [136, 124, 136],\n",
       "        [136, 124, 136],\n",
       "        [136, 124, 136]],\n",
       "\n",
       "       [[ 17,  12,  13],\n",
       "        [ 17,  12,  13],\n",
       "        [ 17,  12,  13],\n",
       "        ...,\n",
       "        [136, 124, 136],\n",
       "        [136, 124, 136],\n",
       "        [136, 124, 136]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[184, 197, 205],\n",
       "        [185, 198, 206],\n",
       "        [184, 197, 205],\n",
       "        ...,\n",
       "        [134, 154, 176],\n",
       "        [135, 155, 177],\n",
       "        [135, 155, 177]],\n",
       "\n",
       "       [[185, 198, 206],\n",
       "        [185, 198, 206],\n",
       "        [186, 199, 207],\n",
       "        ...,\n",
       "        [133, 153, 175],\n",
       "        [134, 154, 176],\n",
       "        [134, 154, 176]],\n",
       "\n",
       "       [[185, 198, 206],\n",
       "        [185, 198, 206],\n",
       "        [185, 198, 206],\n",
       "        ...,\n",
       "        [124, 144, 166],\n",
       "        [125, 145, 167],\n",
       "        [125, 145, 167]]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07d0bc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def load_image_features(img_paths=[]):\n",
    "    # -----------------------------------------------------\n",
    "    # Define tensorflow model\n",
    "    # https://gist.github.com/eerwitt/518b0c9564e500b4b50f\n",
    "    # -----------------------------------------------------\n",
    "    # 定義 graph (tensor 和 flow)\n",
    "    filename_queue = tf.train.string_input_producer(img_paths, shuffle=False)\n",
    "    image_reader = tf.WholeFileReader()\n",
    "    file_name, file_content = image_reader.read(filename_queue)\n",
    "    decoded_image = tf.image.decode_png(file_content, channels=3)\n",
    "    resized_image = tf.image.resize_images(decoded_image, [30, 30])\n",
    "\n",
    "    final_image_ary = []\n",
    "    # 執行 graph\n",
    "    with tf.Session() as sess:\n",
    "        # 執行tensorflow時要先初始化\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(coord=coord) # 建立多執行緒\n",
    "\n",
    "        # image to RGB\n",
    "        for i in range(len(img_paths)):\n",
    "            img = sess.run(resized_image)\n",
    "            final_image_ary.append(img)\n",
    "\n",
    "        # 將最後的陣列轉換為 numpy 格式的陣列，以便存檔\n",
    "        final_image_ary = np.array(final_image_ary, dtype=np.uint8)\n",
    "        # 存檔\n",
    "        final_image_ary.tofile(\"./your/image/training/array.features\")\n",
    "\n",
    "        # 停止多執行緒\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "\n",
    "    return final_image_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5de690",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a77a2e31",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './your/image/training/array.features'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# 載入訓練資料集\u001b[39;00m\n\u001b[0;32m     12\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10000\u001b[39m\n\u001b[1;32m---> 13\u001b[0m img_feature \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./your/image/training/array.features\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muint8\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m img_feature \u001b[38;5;241m=\u001b[39m img_feature\u001b[38;5;241m.\u001b[39mreshape(n, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m30\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     15\u001b[0m img_label \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mfromfile(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./your/image/training/array.labels\u001b[39m\u001b[38;5;124m\"\u001b[39m, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39muint8)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './your/image/training/array.features'"
     ]
    }
   ],
   "source": [
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# 設定 np 亂數種子\n",
    "np.random.seed(10)\n",
    "\n",
    "# 載入訓練資料集\n",
    "n = 10000\n",
    "img_feature = np.fromfile(\"./your/image/training/array.features\", dtype=np.uint8)\n",
    "img_feature = img_feature.reshape(n, 30, 30, 3)\n",
    "img_label = np.fromfile(\"./your/image/training/array.labels\", dtype=np.uint8)\n",
    "img_label = img_label.reshape(n, 1)\n",
    "\n",
    "# 打散資料集\n",
    "indexs = np.random.permutation(img_label.shape[0])\n",
    "rand_img_feature = img_feature[indexs]\n",
    "rand_img_label = img_label[indexs]\n",
    "\n",
    "# 資料正規化\n",
    "# 將 feature 數字轉換為 0~1 的浮點數，能加快收斂，並提升預測準確度\n",
    "# 把維度 (n,30,30,3) => (n, 30*30*3)後，再除255\n",
    "img_feature_normalized = rand_img_feature.reshape(n, 30*30*3).astype('float32') / 255\n",
    "\n",
    "# 將 label 轉換為 onehot 表示\n",
    "img_label_onehot = np_utils.to_categorical(rand_img_label)\n",
    "\n",
    "# 建立一個線性堆疊模型\n",
    "model = Sequential()\n",
    "\n",
    "# 建立輸入層與隱藏層\n",
    "model.add(Dense(input_dim = 30*30*3, # 輸入層神經元數\n",
    "                units = 1000, # 隱藏層神經元數\n",
    "                kernel_initializer = 'normal', # 權重和誤差初始化方式:normal，使用常態分佈產生出始值\n",
    "                activation = 'relu')) # 激活函數:relu函數，忽略掉負數的值\n",
    "\n",
    "# 建立輸出層\n",
    "model.add(Dense(units = 2, # 輸出層神經元數 (即[True, False])\n",
    "                kernel_initializer = 'normal',\n",
    "                activation = 'softmax')) # 激活函數:softmax函數，使輸出介於 0~1 之間\n",
    "\n",
    "# 定義訓練方式\n",
    "model.compile(loss='categorical_crossentropy', # 損失函數\n",
    "             optimizer='adam', # 最佳化方法\n",
    "             metrics=['accuracy']) # 評估方式:準確度\n",
    "\n",
    "# 顯示模型摘要\n",
    "print(model.summary())\n",
    "\n",
    "# 開始訓練模型\n",
    "train_history = model.fit(x=img_feature_normalized, # 指定 feature\n",
    "                          y=img_label_onehot, # 指定 label \n",
    "                          validation_split=0.2, # 分80%訓練，20%驗證\n",
    "                          epochs=5, # 執行 5 次訓練\n",
    "                          batch_size=200, # 批次訓練，每批次 200 筆資料\n",
    "                          verbose=2) # 顯示訓練過程\n",
    "\n",
    "# 儲存模型\n",
    "model.save(\"./your/image/training/models.dat\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259368e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28dd4187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d99e6b5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sampleproject\n",
      "  Downloading sampleproject-3.0.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting peppercorn\n",
      "  Downloading peppercorn-0.6-py3-none-any.whl (4.8 kB)\n",
      "Installing collected packages: peppercorn, sampleproject\n",
      "Successfully installed peppercorn-0.6 sampleproject-3.0.0\n"
     ]
    }
   ],
   "source": [
    "!pip install sampleproject\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d69a0da",
   "metadata": {},
   "source": [
    "### 2.读取视频并从每一帧中提取图像。您可以使用OpenCV库来读取视频并从每一帧中提取图像。您可以选择将每一帧图像保存为图像文件或将其存储在内存中以进行后续处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1920e3ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b29141b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'process_frame' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 19\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# 对每一帧进行处理，提取图像\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m image \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_frame\u001b[49m(frame)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# 保存图像到文件或将其存储在内存中\u001b[39;00m\n\u001b[0;32m     22\u001b[0m save_image(image)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'process_frame' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "# 检查视频是否成功打开\n",
    "if not cap.isOpened():\n",
    "    print('Could not open video file.')\n",
    "    \n",
    "    \n",
    " \n",
    "# 循环读取每一帧\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    # 检查是否成功读取帧\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # 对每一帧进行处理，提取图像\n",
    "\n",
    "    image = process_frame(frame)\n",
    "\n",
    "    # 保存图像到文件或将其存储在内存中\n",
    "    save_image(image)\n",
    "    images.append(image)\n",
    "\n",
    "# 释放视频资源\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e81f9eb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "< cv2.VideoCapture 0000015380D09D30>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6cd22e4",
   "metadata": {},
   "source": [
    "### 3.对提取的图像进行预处理。您可以使用常用的图像处理技术来准备图像数据，例如调整大小、调整亮度、对比度、标准化等。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df7cd18e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_frame(frame):\n",
    "    # 调整大小\n",
    "    frame = cv2.resize(frame, (224, 224))\n",
    "\n",
    "    # 调整亮度和对比度\n",
    "    alpha = 1.5  # 控制亮度\n",
    "    beta = 50  # 控制对比度\n",
    "    frame = cv2.convertScaleAbs(frame, alpha=alpha, beta=beta)\n",
    "\n",
    "    # 标准化\n",
    "    frame = frame.astype(np.float32) / 255.0\n",
    "\n",
    "    return frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee3bf27f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "db535969",
   "metadata": {},
   "source": [
    "### 4.创建标签并将数据分为训练集和测试集。您需要为每个图像分配一个标签。例如，如果您要训练模型以识别人的行走动作，则可以将走路的图像标记为“1”，并将其他动作标记为“0”。您可以将数据分为训练集和测试集，以便在训练模型之前评估模型的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1d179197",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'images' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# 创建标签\u001b[39;00m\n\u001b[0;32m      2\u001b[0m labels \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mimages\u001b[49m)):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(images) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m      5\u001b[0m         labels\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'images' is not defined"
     ]
    }
   ],
   "source": [
    "# 创建标签\n",
    "labels = []\n",
    "for i in range(len(images)):\n",
    "    if i < len(images) / 2:\n",
    "        labels.append(1)\n",
    "    else:\n",
    "        labels.append(0)\n",
    "\n",
    "# 将数据分为训练集和测试集\n",
    "x_train = np.array(images[:len(images) // 2])\n",
    "y_train = np.array(labels[:len(labels) // 2])\n",
    "x_test = np.array(images[len(images) // 2:])\n",
    "y_test = np.array(labels[len(labels) // 2:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d1928e",
   "metadata": {},
   "source": [
    "## Keras\n",
    "### 1定義模型\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebac0a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(256, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f342065",
   "metadata": {},
   "source": [
    "### 2編譯模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "109b908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcab9ee6",
   "metadata": {},
   "source": [
    "### 3訓練模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38579196",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(\u001b[43mx_train\u001b[49m, y_train, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39m(x_test, y_test))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=32, epochs=10, validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29747cc7",
   "metadata": {},
   "source": [
    "### 4.评估模型性能。在训练完成后，您可以使用evaluate()函数来评估模型在测试集上的性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3396d68",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m score \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(\u001b[43mx_test\u001b[49m, y_test)\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest loss:\u001b[39m\u001b[38;5;124m'\u001b[39m, score[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTest accuracy:\u001b[39m\u001b[38;5;124m'\u001b[39m, score[\u001b[38;5;241m1\u001b[39m])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_test' is not defined"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedeeba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be9bb643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b442abf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707b8cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "假設你已經有這些資料的字典或列表，以下是一段可以轉換成 Keras 可以吃進去的 NormalizedLandmarkList 的程式碼：\n",
    "\n",
    "python\n",
    "Copy code\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "\n",
    "# 創建Mixed Precision Policy以提高運行效率\n",
    "policy = mixed_precision.Policy('float32')\n",
    "mixed_precision.set_policy(policy)\n",
    "\n",
    "# 創建NormalizedLandmarkList\n",
    "nl_list = tf.keras.mixed_precision.Policy('float32').numpy_dtype(tf.constant([]))\n",
    "\n",
    "for i in range(13, 29):\n",
    "    x = skeleton[f'{i}']['x']\n",
    "    y = skeleton[f'{i}']['y']\n",
    "    z = skeleton[f'{i}']['z']\n",
    "    visibility = skeleton[f'{i}']['visibility']\n",
    "    nl = np.array([x, y, z, visibility], dtype=np.float32)\n",
    "    nl_list = np.append(nl_list, nl)\n",
    "\n",
    "nl_list = nl_list.reshape(-1, 4)\n",
    "normalized_landmark_list = tf.expand_dims(nl_list, axis=0)\n",
    "\n",
    "print(normalized_landmark_list)\n",
    "輸出的 normalized_landmark_list 的形狀會是 (1, 16, 4)，也就是一個大小為 1x16x4 的張量，其中第一個維度是樣本數，第二個維度是輸入的關鍵點數量，第三個維度是每個關鍵點的屬性數量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b714953",
   "metadata": {},
   "outputs": [],
   "source": [
    "您可以使用 Python 的字典（dict）資料結構來儲存 lm 資訊。以下是一個示範程式碼：\n",
    "\n",
    "python\n",
    "Copy code\n",
    "cap = cv2.VideoCapture('sean.mp4')\n",
    "pTime = 0\n",
    "landmarks_dict = {}  # 建立空的字典\n",
    "\n",
    "while True :\n",
    "    success,img = cap.read()\n",
    "    imgRGB = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "    results = pose.process(imgRGB)\n",
    "    #print(results.pose_landmarks) #顯示每個值\n",
    "    \n",
    "    if results.pose_landmarks:   \n",
    "        mpDraw.draw_landmarks(img , results.pose_landmarks,mpPose.POSE_CONNECTIONS)\n",
    "        for id ,lm in enumerate(results.pose_landmarks.landmark):   #找出landmarks的點\n",
    "            h ,w ,c = img.shape\n",
    "            print(id ,lm)  #顯示33個mark\n",
    "            cx , cy  =int(lm.x * w ), int(lm.y * h)  #像素質\n",
    "            cv2.circle( img , (cx , cy), 5 , (255,255,0) , cv2.FILLED   )\n",
    "            landmarks_dict[id] = {'x': lm.x, 'y': lm.y, 'z': lm.z, 'visibility': lm.visibility}  # 將 lm 資訊存入字典\n",
    "        \n",
    "    cTime = time.time()\n",
    "    fps = 1/(cTime- pTime)\n",
    "    pTime = cTime\n",
    "    \n",
    "    cv2.putText(img , str(int(fps)),(70,50), cv2.FONT_HERSHEY_PLAIN,3,(255,0,0) , 3)\n",
    "    \n",
    "    cv2.imshow(\"Image\",img)\n",
    "    cv2.waitKey(5)\n",
    "    \n",
    "print(landmarks_dict)  # 顯示存有所有 lm 資訊的字典"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
